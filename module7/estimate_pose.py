import numpy as np
import cv2
import os

# --- Configuration ---
# 1. Camera Intrinsics file generated by calibrate_camera.py
INTRINSICS_FILE = 'camera_calibration.npz'
# 2. Input images (assuming they are in a 'static' folder or similar location accessible to Flask)
IMAGE_LEFT = 'static/image_L.jpg'
IMAGE_RIGHT = 'static/image_R.jpg'
# 3. Output file for the stereo matrices
OUTPUT_STEREO_FILE = 'stereo_calibration.npz'


def load_intrinsics(filename):
    """Loads the camera matrix (K) and distortion coefficients (dist) from file."""
    if not os.path.exists(filename):
        raise FileNotFoundError(f"Error: Intrinsics file '{filename}' not found. Run calibrate_camera.py first.")

    data = np.load(filename)
    K = data['camera_matrix']
    dist = data['dist_coeffs']
    print(f"Intrinsics K:\n{K}")
    return K, dist


def estimate_and_rectify_pose():
    """Performs feature matching, essential matrix calculation, and stereo rectification."""

    K, dist = load_intrinsics(INTRINSICS_FILE)

    img1 = cv2.imread(IMAGE_LEFT, cv2.IMREAD_GRAYSCALE)
    img2 = cv2.imread(IMAGE_RIGHT, cv2.IMREAD_GRAYSCALE)

    if img1 is None or img2 is None:
        raise FileNotFoundError(
            "Error: One or both stereo images (image_L.jpg, image_R.jpg) not found or cannot be loaded.")

    h, w = img1.shape
    img_size = (w, h)

    # 1. Feature Detection and Matching (using ORB, a fast descriptor)
    orb = cv2.ORB_create()
    kp1, des1 = orb.detectAndCompute(img1, None)
    kp2, des2 = orb.detectAndCompute(img2, None)

    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    matches = bf.match(des1, des2)

    # Sort matches by distance (best matches first)
    matches = sorted(matches, key=lambda x: x.distance)

    # Use the top N matches (e.g., top 100)
    num_matches = min(len(matches), 100)
    good_matches = matches[:num_matches]

    # Extract matching points
    pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
    pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)

    if len(pts1) < 8:
        print("Error: Not enough good matches found (need at least 8). Pose estimation failed.")
        return

    print(f"Found {len(pts1)} good feature matches.")

    # 2. Find Essential Matrix (E)
    # The Essential Matrix E relates corresponding image points assuming known intrinsics.
    E, mask = cv2.findEssentialMat(pts1, pts2, K, method=cv2.RANSAC, prob=0.999, threshold=1.0)

    if E is None:
        print("Error: Could not compute Essential Matrix.")
        return

    # 3. Recover Pose (R, T)
    # Decompose E to get the relative Rotation (R) and Translation (T)
    # This gives us the extrinsic parameters of the right camera relative to the left.
    ret, R, T, mask = cv2.recoverPose(E, pts1, pts2, K, mask=mask)

    print(f"Estimated Rotation R:\n{R}")
    print(f"Estimated Translation T (Relative Position):\n{T}")

    # 4. Stereo Rectification and Projection Matrices (P_L, P_R, Q)
    # Since the cameras are the same, we use the same K and dist for both.
    R1, R2, P1, P2, Q, validPixROI1, validPixROI2 = cv2.stereoRectify(
        K, dist,
        K, dist,
        img_size,
        R, T,
        alpha=1  # Sets the output images to be fully visible (no black boundaries)
    )

    print("\n--- Rectification Complete ---")
    print(f"Projection Matrix P_L:\n{P1}")
    print(f"Projection Matrix P_R:\n{P2}")
    print(f"Disparity-to-Depth Matrix Q:\n{Q}")

    # 5. Save the results needed for the web app
    np.savez(OUTPUT_STEREO_FILE, P_L=P1, P_R=P2, Q=Q, K=K, dist=dist)

    print(f"\nSUCCESS: Stereo matrices saved to '{OUTPUT_STEREO_FILE}'.")
    print("You can now run 'app_stereo.py'.")


if __name__ == '__main__':
    estimate_and_rectify_pose()

